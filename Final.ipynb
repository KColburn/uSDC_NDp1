{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarND Novermber Cohort Project 1: Lane Detection\n",
    "## Functions used (including helper)\n",
    "* Weight Image \n",
    "* Grayscale \n",
    "* Canny Edge Detection\n",
    "* Region Selection\n",
    "* Hough Lines\n",
    "* Gaussion Smoothing\n",
    "* Color Selection\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "28f0bdfa-1bde-4084-bdd9-abe30689c92d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "87e4d5dd-ab28-4515-a1c2-2a03b2db4c57"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  ['solidWhiteCurve.jpg', 'solidWhiteRight.jpg', 'solidYellowCurve.jpg', 'solidYellowCurve2.jpg', 'solidYellowLeft.jpg', 'whiteCarLaneSwitch.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "images = os.listdir(\"test_images/\")\n",
    "print('images: ', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "79742d8f-e440-4840-b9d4-4d17ab1e41a4"
    }
   },
   "outputs": [],
   "source": [
    "#reading an image\n",
    "def readImage(image):\n",
    "    image = mpimg.imread('test_images/' + image)\n",
    "    gray = grayscale(image)\n",
    "    blur_gray = apply_gaussian_blur(gray)\n",
    "    edges = apply_canny(blur_gray)\n",
    "    masked_image = apply_mask(edges, image, gray)\n",
    "    hough_image, lines = apply_hough(masked_image)\n",
    "    lines_edges_weighted = apply_lines_edges_weighted(image, edges, hough_image)\n",
    "    plot_mask(edges, image, masked_image)\n",
    "    plot_hough(hough_image, lines)\n",
    "    plot_mask_and_hough(masked_image, hough_image)\n",
    "    plot_weighted_image(lines_edges_weighted)\n",
    "    return lines_edges_weighted\n",
    "\n",
    "#Read each image and output the result\n",
    "def readAllImages(images):\n",
    "    for img in images:\n",
    "        result = readImage(img)\n",
    "        mpimg.imsave('results_rendered/' + '-ChangedParameters--'+img, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have made a loop to read all images we want to convert each image to a grayscale by taking off the RGB valus. By getting rid of the 3rd value we take its 3rd Dimension of color.\n",
    "\n",
    "Then we apply a Guassion Blur filder to reduce noise from the image. It will also smooth out the edges which will help us with our canny edge detector later.\n",
    "* The Gaussian Blur will take a kernel size of 5 to cover the larger area of the images. Kernel sizes are always odd numbers and generally range from 3,5 and 7\n",
    "* We also want to give it a low and high threshold. The recommended ratio is either 1:2 or 1:3 low to high thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "452a9415-6311-45a1-bb38-dab0378d4206"
    }
   },
   "outputs": [],
   "source": [
    "#Apply Gaussian Blur\n",
    "def apply_gaussian_blur(gray, kernel_size = 5):\n",
    "    return gaussian_blur(gray, kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've applied our Gaussian Blur we will apply canny using the image and the low and high thresholds.\n",
    "* Any values below the low threshold will be discard and anything aboe the high threshold will be considereed edges\n",
    "* We've set the low threshold to be 75 and the high threshold to be 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e2611312-f1b1-4cd2-bcb7-c2a0e8498083"
    }
   },
   "outputs": [],
   "source": [
    "#Define parameters for Canny Edge Detector\n",
    "def apply_canny(blur_gray, low_threshold = 75, high_threshold = 175):\n",
    "    return canny(blur_gray, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply and image mask so it only considers the lane lines and plot the mask so we get our region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9340fa22-c308-48ac-920b-aa7dc5d67c7d"
    }
   },
   "outputs": [],
   "source": [
    "def apply_mask(edges, image, gray):\n",
    "\n",
    "    mask = np.zeros_like(edges)\n",
    "    \n",
    "    ignore_mask_color = 255 \n",
    "\n",
    "    imshape = image.shape\n",
    "\n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "    \n",
    "    x_middle = xsize/2\n",
    "    x_offset = 55\n",
    "    \n",
    "    y_middle = ysize/2\n",
    "    y_offset = 45\n",
    "    vertices = np.array([[(0, ysize),(x_middle - x_offset, y_middle + y_offset), (x_middle + x_offset, y_middle + y_offset), \n",
    "                          (xsize, ysize)]], dtype=np.int32)\n",
    "    \n",
    "\n",
    "    #fillPoly the mask\n",
    "    (masked_image, mask) = region_of_interest(edges, vertices)\n",
    "    return masked_image\n",
    "\n",
    "def plot_mask(edges, image, masked_image):\n",
    "    #Plotting each of the images using subplot\n",
    "    fig = plt.figure()\n",
    "\n",
    "    add = fig.add_subplot(3,1,1)\n",
    "    edgeplot = plt.imshow(edges, cmap=\"gray\")\n",
    "    add.set_title('Edges')\n",
    "\n",
    "    add = fig.add_subplot(3,1,2)\n",
    "    add.set_title('Image')\n",
    "    edgeplot = plt.imshow(image)\n",
    "\n",
    "    add = fig.add_subplot(3,1,3)\n",
    "    add.set_title('Masked Image')\n",
    "    edgeplot = plt.imshow(masked_image, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've applied the image mask it's time to apply the hough transformation and create the lines on the masked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0f838ff3-2ac1-495e-89cd-652b711949a4"
    }
   },
   "outputs": [],
   "source": [
    "def apply_hough(masked_image):\n",
    "    theta = np.pi/180     \n",
    "    rho = 1.8\n",
    "    threshold = 75\n",
    "    min_line_len = 20\n",
    "    max_line_gap = 120\n",
    "\n",
    "    #Create a line image with hough lines on it\n",
    "    hough_image, lines = hough_lines(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "    return hough_image, lines\n",
    "    #Gave line_image color when we copied the shape of mask_image\n",
    "    #In draw_lines we input color = [255, 0, 0] so that it will be red\n",
    "\n",
    "def plot_hough(hough_image, lines):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    b = fig.add_subplot(2,1,1)\n",
    "    edgeplot = plt.imshow(lines)\n",
    "    b.set_title('Lines')\n",
    "\n",
    "    b = fig.add_subplot(2,2,2)\n",
    "    b.set_title('Hough Image')\n",
    "    edgeplot = plt.imshow(hough_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a line image and a masked image. Now we just apply the line image on top of the mask images and form the two images into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5e26c25a-bc3d-4573-b18f-97169c5beeff"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mask_and_hough(masked_image, hough_image):\n",
    "    fig = plt.figure()\n",
    "    c = fig.add_subplot(1,2,1)\n",
    "    edgeplot = plt.imshow(masked_image, cmap=\"gray\")\n",
    "    c.set_title('masked_image')\n",
    "\n",
    "    c = fig.add_subplot(1,2,2)\n",
    "    c.set_title('Hough_image')\n",
    "    edgeplot = plt.imshow(hough_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cab12ca6-5cc3-49d4-99da-b6d2cd504e6a"
    }
   },
   "outputs": [],
   "source": [
    "#Img is the output of hough lines to line images\n",
    "#initial_image is the color_edges\n",
    "def apply_lines_edges_weighted(image, edges, hough_image):\n",
    "    lines_edges_weighted = weighted_img(hough_image, image)\n",
    "    return lines_edges_weighted\n",
    "\n",
    "def plot_lines_edges_weighted_hough_and_original():\n",
    "    #Plot using subplots\n",
    "    fig = plt.figure()\n",
    "    d = fig.add_subplot(3,1,1)\n",
    "    line_edgeplot = plt.imshow(hough_image)\n",
    "    d.set_title('hough_image')\n",
    "\n",
    "    d = fig.add_subplot(3,1,2)\n",
    "    line_edgeplot = plt.imshow(color_edges)\n",
    "    d.set_title('color_edges')\n",
    "\n",
    "    d = fig.add_subplot(3,1,3)\n",
    "    line_edgeplot = plt.imshow(lines_edges_weighted)\n",
    "    d.set_title('lines_edges_weighted')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_weighted_image(lines_edges_weighted):\n",
    "    plt.imshow(lines_edges_weighted)\n",
    "    \n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8cb7a8de-dba5-4be0-8077-ec932ba54507"
    }
   },
   "outputs": [],
   "source": [
    "#Converts image to grayscale\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Applies canny transform\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "#Applies gaussian noise kernel, typically use kernel size of 3 or 5. (odd numbers only)\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:  #if it is 3 or 4 channels; RGB or RGBT\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count  #so you can fill multiple colors\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    # Because we just filled the mask matrix with vertices in the *fillPoly* function.\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return (masked_image, mask)\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=11):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    x1_values = lines[:, :, 0]\n",
    "    y1_values = lines[:, :, 1]\n",
    "    x2_values = lines[:, :, 2]\n",
    "    y2_values = lines[:, :, 3]\n",
    "\n",
    "\n",
    "    global prev_left_x_min\n",
    "    global prev_left_x_max\n",
    "    global prev_right_x_min\n",
    "    global prev_right_x_max\n",
    "\n",
    "    y_max = max(np.amax(y1_values), np.amax(y2_values))\n",
    "    y_min = max(np.amin(y1_values), np.amin(y2_values))\n",
    "    left_slopes = []\n",
    "    right_slopes = []\n",
    "\n",
    "    right_lane = []\n",
    "    left_lane = []\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "\n",
    "            #if slope < 0:  #left lane has negative slope\n",
    "            if (-0.9 < slope < -0.6):\n",
    "                left_slopes.append(slope)\n",
    "                left_lane.append(line)\n",
    "            elif 0.45 < slope < 0.7: # right lane positive slope\n",
    "                right_slopes.append(slope)\n",
    "                right_lane.append(line)\n",
    "\n",
    "    left_slopes_arr = np.array(left_slopes)\n",
    "    right_slopes_arr = np.array(right_slopes)\n",
    "\n",
    "    left_lines_arr = np.array(left_lane)\n",
    "    right_lines_arr = np.array(right_lane)\n",
    "\n",
    "    # Find average slopes\n",
    "    left_lane_slope_average = np.mean(left_slopes_arr) \n",
    "    right_lane_slope_average = np.mean(right_slopes_arr)\n",
    "\n",
    "    y_max = int(y_max)\n",
    "    y_min = int(y_min)\n",
    "\n",
    "    if len(left_lines_arr) > 0:\n",
    "        #Compute Left lane intercept:\n",
    "        y_intercept_left_lane_average = np.mean(left_lines_arr[:, :, 1] - (left_lines_arr[:, :, 0] * left_lane_slope_average))\n",
    "\n",
    "        #Compute Left lane Xmax and Xmin:\n",
    "        x_max_left = int((y_max - y_intercept_left_lane_average) / left_lane_slope_average)\n",
    "        x_min_left = int((y_min - y_intercept_left_lane_average) / left_lane_slope_average)\n",
    "            \n",
    "\n",
    "        cv2.line(img, (x_max_left, y_max), (x_min_left, y_min), color, thickness)\n",
    "        #Saves the last coordinate to keep the line going from new start point\n",
    "        \n",
    "        prev_left_x_max = x_max_left\n",
    "        prev_left_x_min = x_min_left\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if prev_left_x_max is not None:\n",
    "            print('prev_left_x_max is not None')\n",
    "            cv2.line(img, (prev_left_x_max, y_max),(prev_left_x_min, y_min), color, thickness)\n",
    "        else:\n",
    "            print('nothing')\n",
    "            \n",
    "    if len(right_lines_arr) > 0:\n",
    "        # Compute Right Lane Intercept:\n",
    "        y_intercept_right_lane_average = np.mean(right_lines_arr[:, :, 1] - (right_lines_arr[:, :, 0] * right_lane_slope_average))\n",
    "\n",
    "        # Compute Right lane Xmax and Xmin:\n",
    "        x_max_right = int((y_max - y_intercept_right_lane_average) / right_lane_slope_average)\n",
    "        x_min_right = int((y_min - y_intercept_right_lane_average) / right_lane_slope_average)\n",
    "\n",
    "        cv2.line(img, (x_max_right, y_max), (x_min_right, y_min), color, thickness)\n",
    "        prev_right_x_max = x_max_right\n",
    "        prev_right_x_min = x_min_right\n",
    "    else:\n",
    "        if prev_right_x_max is not None:\n",
    "            print('prev_right_x_max is not NONE')\n",
    "            cv2.line(img, (prev_right_x_max, y_max), (prev_right_x_min, y_min), color, thickness)\n",
    "        else:\n",
    "            \n",
    "            print('nothing right side empty')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        img shape will be 2D output from canny transform\n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    hough_lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,\n",
    "                                  maxLineGap=max_line_gap)\n",
    "\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)  \n",
    "\n",
    "    draw_lines(line_img, hough_lines)\n",
    "    return (line_img, hough_lines)\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b3553e2f-44b5-4490-a6df-c949080a46eb"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Save previous coordinates as global variables in case program doesn't detect any lines fromp previous iteration\n",
    "prev_left_x_min = None\n",
    "prev_left_x_max = None\n",
    "prev_right_x_min = None\n",
    "prev_right_x_max = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "da4fa3ae-48ba-4e62-a5ee-17135880c7c0"
    }
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "    blur_gray = apply_gaussian_blur(gray)\n",
    "    edges = apply_canny(blur_gray)\n",
    "    masked_image = apply_mask(edges, image, gray)\n",
    "    hough_image, lines = apply_hough(masked_image)\n",
    "    lines_edges_weighted = apply_lines_edges_weighted(image, edges, hough_image)\n",
    "    return lines_edges_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0c70875a-49e2-4036-91c5-c1788118fad3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video submit-solidWhiteRightx2.mp4\n",
      "[MoviePy] Writing video submit-solidWhiteRightx2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▎                              | 137/222 [00:01<00:01, 69.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 207/222 [00:02<00:00, 71.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 221/222 [00:03<00:00, 73.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: submit-solidWhiteRightx2.mp4 \n",
      "\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test on solidWhite\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'submit-solidWhiteRightx2.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8e06a3c2-138e-4920-8fb8-4ead24edbad7"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"submit-solidWhiteRightx2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4ed4430d-ae22-4ab1-aa9b-674ff56bd2f6"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video submit-solidYellowLeftTestx2.mp4\n",
      "[MoviePy] Writing video submit-solidYellowLeftTestx2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▉| 681/682 [00:09<00:00, 71.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: submit-solidYellowLeftTestx2.mp4 \n",
      "\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test on solid yellow left\n",
    "yellow_output = 'submit-solidYellowLeftTestx2.mp4'\n",
    "clip2 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "yellow_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "83a9b433-ed7c-4e16-ac09-c8b3f4f2beb3"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1000\" height=\"600\" controls>\n",
       "  <source src=\"submit-solidYellowLeftTestx2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"1000\" height=\"600\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0cfdd001-fdb0-46e8-b549-cede1ba46a7f"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                        | 26/251 [00:00<00:04, 46.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▎                                                  | 94/251 [00:02<00:04, 36.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▋                                                 | 98/251 [00:02<00:04, 37.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▊                                              | 106/251 [00:02<00:03, 36.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████                                             | 110/251 [00:02<00:04, 34.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▎                                           | 114/251 [00:02<00:04, 34.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▌                                          | 118/251 [00:02<00:04, 33.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|██████████████████████████████████████▉                                         | 122/251 [00:03<00:04, 28.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▊                                        | 125/251 [00:03<00:04, 28.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_right_x_max is not NONE\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████████████████████████                                       | 129/251 [00:03<00:04, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▍                                     | 133/251 [00:03<00:03, 30.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▋                                    | 137/251 [00:03<00:04, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▉                                   | 141/251 [00:03<00:04, 26.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▉                                  | 144/251 [00:03<00:04, 25.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████▊                                 | 147/251 [00:04<00:04, 25.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 158/251 [00:04<00:03, 29.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n",
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 251/251 [00:07<00:00, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "Wall time: 8.01 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4cf09606-e6f7-4854-8ee0-cc4ffe246a29"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection: \n",
    "I spent most of my time figuring out which functions to use from the list of helper functions then finding a way to put it all together. I'm fairly new to python and I've never used jupyter notebook before but thanfully with the help of my mentor, some information from the forums, the P1 slack group conversation and some ideas from JonathanCMitchell's Git repository I was able to get the environment installed and running fine fairly quickly and get started on the project. I had the idea of how to create the project for a while but it took me a lot of time to figure out how to implement it all and put it together on notebook. I'm pretty sattisfied with the result of the video tests overall. However, if I were to try to improve on one thing it would be the result of the challenge video. I tried just slightly changing the slope of the original formula for the base videos but it didn't work out as well as I had hoped for the challenge. I would definitely love to try and figure out a way to create curved lines that would automatically follow the traffic lines using hough and canny edge. I think it would be a further change in slope but I'm not entirely sure. All in all it was a great project and I'm very excited to continue learning and start the next project."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
